{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5622daa987f5dca8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Make sure the dataset from huggingface is also not clean for climateQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T13:31:17.675855900Z",
     "start_time": "2024-08-21T13:31:13.586087500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87344032e02573d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T13:31:21.683591700Z",
     "start_time": "2024-08-21T13:31:19.649931100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), \"data/non-dataset/climabench/all_data/CDP/Corporations/Corporations Responses/Climate Change/2018_Full_Climate_Change_Dataset.csv\") \n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868c27f5800a075",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405d1dc8597289c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T15:42:10.590175500Z",
     "start_time": "2024-08-21T15:42:08.675703600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "completed_df = pd.concat([\n",
    "    pd.read_csv(os.path.join(os.getcwd(), \"data/non-dataset/climabench/all_data/CDP/Corporations/Corporations Responses/Climate Change/test_qa.csv\")),\n",
    "    pd.read_csv(os.path.join(os.getcwd(), \"data/non-dataset/climabench/all_data/CDP/Corporations/Corporations Responses/Climate Change/train_qa.csv\")),\n",
    "    pd.read_csv(os.path.join(os.getcwd(), \"data/non-dataset/climabench/all_data/CDP/Corporations/Corporations Responses/Climate Change/val_qa.csv\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f8a4bf54b68ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T15:42:10.927117800Z",
     "start_time": "2024-08-21T15:42:10.590175500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_df = df[df['response_value'].isin(completed_df['answer'])]\n",
    "filtered_df = filtered_df[~filtered_df.duplicated(subset=['question_unique_reference', 'response_value'], keep=\"first\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d903b69e9596b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T15:45:26.084089Z",
     "start_time": "2024-08-21T15:45:26.003456600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train, test, dev split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "selftrain_test_split = 0.2\n",
    "selftest_dev_split = 0.5\n",
    "\n",
    "train, temp = train_test_split(filtered_df, test_size=selftrain_test_split, random_state=seed, shuffle=True)\n",
    "dev, test = train_test_split(temp, test_size=selftest_dev_split, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3730e53a86cb5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T15:51:23.680806400Z",
     "start_time": "2024-08-21T15:47:37.422422Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Function to generate false answers\n",
    "def generate_false_answers(df):\n",
    "    \n",
    "    false_answers = []\n",
    "    \n",
    "    for i, r in df.iterrows():\n",
    "        answer = r['response_value']\n",
    "        question = r['question_unique_reference']\n",
    "        \n",
    "        found = False\n",
    "        while not found:\n",
    "            sample = df.sample(1)\n",
    "            \n",
    "            found = True\n",
    "                        \n",
    "            if sample['response_value'].values[0] == answer:\n",
    "                found = False\n",
    "                continue\n",
    "                \n",
    "            if sample['question_unique_reference'].values[0] == question:\n",
    "                found = False\n",
    "                continue\n",
    "                \n",
    "            if question in df[df['response_value'] == sample['response_value'].values[0]]['question_unique_reference'].unique().tolist():\n",
    "                found = False\n",
    "                continue\n",
    "                \n",
    "        false_answers += [sample['response_value'].values[0]]\n",
    "    \n",
    "    df['false_response_value'] = false_answers\n",
    "    return df\n",
    "\n",
    "# Generate the false answers\n",
    "train = generate_false_answers(train)\n",
    "test = generate_false_answers(test)\n",
    "dev = generate_false_answers(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636279bf2bd472d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T15:57:19.436370200Z",
     "start_time": "2024-08-21T15:57:19.021619500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[['question_unique_reference', 'response_value', 'false_response_value']].to_parquet(\"data/Climabench/ClimaQA/CustomDataset/train.pkl\")\n",
    "test[['question_unique_reference', 'response_value', 'false_response_value']].to_parquet(\"data/Climabench/ClimaQA/CustomDataset/test.pkl\")\n",
    "dev[['question_unique_reference', 'response_value', 'false_response_value']].to_parquet(\"data/Climabench/ClimaQA/CustomDataset/dev.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639022a1e13e87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T16:01:45.323993900Z",
     "start_time": "2024-08-21T16:01:45.011207500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def explode_df(df):\n",
    "    df_1 = df[['question_unique_reference', 'response_value']].copy()\n",
    "    df_1.columns = [\"query\", \"text\"]\n",
    "    df_1['label'] = 1\n",
    "    \n",
    "    df_2 = df[['question_unique_reference', 'false_response_value']].copy()\n",
    "    df_2.columns = [\"query\", \"text\"]\n",
    "    df_2['label'] = 0\n",
    "    \n",
    "    return pd.concat([\n",
    "        df_1,\n",
    "        df_2\n",
    "    ])\n",
    "\n",
    "explode_df(train).to_parquet(\"data/Climabench/ClimaQA/CustomDataset/train.pkl\")\n",
    "explode_df(test).to_parquet(\"data/Climabench/ClimaQA/CustomDataset/test.pkl\")\n",
    "explode_df(dev).to_parquet(\"data/Climabench/ClimaQA/CustomDataset/dev.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4ed0bbe2e01157",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create a new dataset for ClimaINS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11b266e86045e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:57:23.393432200Z",
     "start_time": "2024-09-03T13:57:23.386067300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from experiment import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc4c98255ff8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:56:44.873268200Z",
     "start_time": "2024-09-03T13:56:44.702287200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test, dev = load_dataset(\"ClimaINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ecf67f2ba884b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:09:37.867322600Z",
     "start_time": "2024-09-03T14:09:37.855183300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dataset = pd.concat([train, test, dev], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ee86b5b9c1df0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:09:42.786323700Z",
     "start_time": "2024-09-03T14:09:42.758505100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2adf5f1e9d310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:09:50.461313Z",
     "start_time": "2024-09-03T14:09:50.387496600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dataset = full_dataset.drop_duplicates()\n",
    "len(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee07c1187e33fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:10:22.136285100Z",
     "start_time": "2024-09-03T14:10:22.105130300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(full_dataset[full_dataset['token_counts']<5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633b3d8bef4a766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:10:29.770156700Z",
     "start_time": "2024-09-03T14:10:29.734167400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dataset = full_dataset[full_dataset['token_counts']>=5].copy()\n",
    "len(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcecdca6c35831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:10:50.648133600Z",
     "start_time": "2024-09-03T14:10:50.585238900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dataset = full_dataset.drop_duplicates(subset=['clean_text', 'label'])\n",
    "len(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399d5a1ed82a273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:12:27.545207700Z",
     "start_time": "2024-09-03T14:12:27.518126600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dataset = full_dataset.drop_duplicates(subset=['clean_text'], keep=False)\n",
    "len(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8907b13a0556d798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:14:34.842101100Z",
     "start_time": "2024-09-03T14:14:34.812398800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_test_split_frac = 0.8\n",
    "test_dev_split_frac = 0.5\n",
    "seed = 42\n",
    "\n",
    "temp, train = train_test_split(full_dataset, test_size=train_test_split_frac, random_state=seed, shuffle=True)\n",
    "dev, test = train_test_split(temp, test_size=test_dev_split_frac, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2b1a71e51c70f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:17:31.351231700Z",
     "start_time": "2024-09-03T14:17:31.152071700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.to_parquet('data/green_nlp_tasks/ClimaINS/train.pkl')\n",
    "test.to_parquet('data/green_nlp_tasks/ClimaINS/test.pkl')\n",
    "dev.to_parquet('data/green_nlp_tasks/ClimaINS/dev.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4bcaae5a90111",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## New dataset created froms scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448afdb0852a0b17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T09:20:32.275972800Z",
     "start_time": "2024-09-16T09:20:30.393918800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from src.builder import clean_text\n",
    "\n",
    "raw_data = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(\"data/non-dataset/climabench/all_data/ClimateInsurance/raw/\"):\n",
    "    \n",
    "    df = pd.read_csv(f\"data/non-dataset/climabench/all_data/ClimateInsurance/raw/{file}\", encoding=\"latin-1\")\n",
    "\n",
    "    for i in range(0, 9):\n",
    "        if f\"Question {i}\" in df.columns:\n",
    "            answers = df[[f\"Question {i}\", \"Year\", \"Company Name\"]].copy()\n",
    "            answers.rename(columns={f\"Question {i}\":\"text\"}, inplace=True)\n",
    "            answers['label'] = i\n",
    "            break\n",
    "\n",
    "    raw_data = pd.concat([raw_data, answers], ignore_index=True)\n",
    "    \n",
    "raw_data.sort_values(by=\"Year\", ascending=False, inplace=True)\n",
    "raw_data['text'] = raw_data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722734e41e74d82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T10:20:07.853598400Z",
     "start_time": "2024-09-16T10:20:07.338571100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"raw dataset\", len(raw_data))\n",
    "print(\"duplicates by year\", len(raw_data[raw_data.duplicated(subset=['text', 'Company Name', 'label'], keep=\"first\")]))\n",
    "print(\"duplicates by company name\", len(raw_data[raw_data.duplicated(subset=['text', 'label', 'Year'], keep=\"first\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c4efde2c3ab20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T13:40:02.984989700Z",
     "start_time": "2024-09-16T13:40:02.924209400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data_1 = raw_data.drop_duplicates(subset=[\"text\"], keep=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f403d98b3cc5c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T14:12:42.720310200Z",
     "start_time": "2024-09-16T14:09:25.104500100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from src.builder import clean_text\n",
    "\n",
    "raw_data = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(\"data/non-dataset/climabench/all_data/ClimateInsurance/raw/\"):\n",
    "    \n",
    "    df = pd.read_csv(f\"data/non-dataset/climabench/all_data/ClimateInsurance/raw/{file}\", encoding=\"latin-1\")\n",
    "\n",
    "    for i in range(0, 9):\n",
    "        if f\"Question {i}\" in df.columns:\n",
    "            answers = df[[f\"Question {i}\", \"Year\", \"Company Name\"]].copy()\n",
    "            answers.rename(columns={f\"Question {i}\":\"text\"}, inplace=True)\n",
    "            answers['label'] = i\n",
    "            break\n",
    "\n",
    "    raw_data = pd.concat([raw_data, answers], ignore_index=True)\n",
    "    \n",
    "raw_data.sort_values(by=\"Year\", ascending=False, inplace=True)\n",
    "raw_data['text'] = raw_data['text'].apply(clean_text)\n",
    "\n",
    "raw_data_1 = raw_data.drop_duplicates(subset=[\"text\"], keep=False).copy()\n",
    "\n",
    "def remove_company_name(row):\n",
    "    text = row['text']\n",
    "    company_name = row['Company Name']\n",
    "    # Escape special characters in company name and compile regex pattern (case-insensitive)\n",
    "    pattern = re.compile(re.escape(company_name), re.IGNORECASE)\n",
    "    # Substitute the company name with an empty string\n",
    "    cleaned_text = pattern.sub('', text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "# Apply the function to create a new column with the cleaned text\n",
    "raw_data_1['cleaned_text'] = raw_data_1.apply(remove_company_name, axis=1)\n",
    "\n",
    "import string\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Check for duplicates in the cleaned text\n",
    "raw_data_1['cleaned_text'] = raw_data_1['cleaned_text'].apply(lambda x: normalize_text(x))\n",
    "duplicates = raw_data_1[raw_data_1.duplicated('cleaned_text', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "duplicates[['cleaned_text', 'text', 'Year', 'Company Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0efb045992bbfa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-16T14:09:23.324168200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Loop over each unique company\n",
    "for c in raw_data_1['Company Name'].unique():\n",
    "    # Filter data for the current company\n",
    "    company_data = raw_data_1[raw_data_1['Company Name'] == c]\n",
    "    \n",
    "    # Extract texts, indices, labels, and years\n",
    "    texts = company_data['text'].tolist()\n",
    "    indices = company_data.index.tolist()\n",
    "    labels = company_data['label'].tolist()  # Assuming 'label' is the column name\n",
    "    years = company_data['Year'].tolist()    # Assuming 'Year' is the column name\n",
    "    \n",
    "    # Combine indices, texts, labels, and years into a list of tuples\n",
    "    data_tuples = list(zip(indices, texts, labels, years))\n",
    "    \n",
    "    # Generate all unique pairs of data\n",
    "    for (idx1, text1, label1, year1), (idx2, text2, label2, year2) in combinations(data_tuples, 2):\n",
    "        # Calculate the Levenshtein distance between the pair of texts\n",
    "        dist = distance(text1, text2)\n",
    "        \n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'Company Name': c,\n",
    "            'Index1': idx1,\n",
    "            'Index2': idx2,\n",
    "            'Label1': label1,\n",
    "            'Label2': label2,\n",
    "            'Year1': year1,\n",
    "            'Year2': year2,\n",
    "            'Text1': text1,\n",
    "            'Text2': text2,\n",
    "            'Distance': dist\n",
    "        })\n",
    "\n",
    "# Convert the results into a DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Optional: Sort the DataFrame by distance to find the closest matches\n",
    "results_df = results_df.sort_values(by='Distance')\n",
    "\n",
    "# Display the closest matches\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b65d15118cc19",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create a dataset for climaTOPIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db2ebdae7304417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:28:24.643138Z",
     "start_time": "2024-09-03T14:28:24.433888600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from experiment import load_dataset\n",
    "import pandas as pd\n",
    "train, test, dev = load_dataset(\"ClimaTOPIC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244050a85f020b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:29:16.636089Z",
     "start_time": "2024-09-03T14:29:16.569931900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.merge(test, how=\"inner\", on=\"clean_text\", suffixes=(\"_train\", \"_test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0e610bde0fba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:28:15.040981600Z",
     "start_time": "2024-09-03T14:28:15.002208600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_dataset = pd.concat([train, test, dev], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0cec46a855f0ee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create Multilabel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c482970746028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:48:46.224262600Z",
     "start_time": "2024-09-05T16:48:45.516366900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.builder import DatasetBuilder\n",
    "\n",
    "logger = generator.logger\n",
    "args = generator.args\n",
    "\n",
    "builder = DatasetBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc8ea4980ecc3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:49:34.335523900Z",
     "start_time": "2024-09-05T16:49:08.894300700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test, dev = builder.lobbymap_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1943f5b0f2a648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:54:45.297442900Z",
     "start_time": "2024-09-05T16:54:44.874755400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.to_parquet(\"data/lobbymap/lobbymap_dataset/train_query.pkl\")\n",
    "test.to_parquet(\"data/lobbymap/lobbymap_dataset/test_query.pkl\")\n",
    "dev.to_parquet(\"data/lobbymap/lobbymap_dataset/dev_query.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99179e09f8288404",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T17:56:28.859942900Z",
     "start_time": "2024-09-05T17:56:28.785446100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/logicclimate/climate_train.csv\")\n",
    "test = pd.read_csv(\"data/logicclimate/climate_test.csv\")\n",
    "dev = pd.read_csv(\"data/logicclimate/climate_dev.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6873c91366bc51f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T17:56:30.786357300Z",
     "start_time": "2024-09-05T17:56:30.763350700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['source_article'])\n",
    "test = test.dropna(subset=['source_article'])\n",
    "dev = dev.dropna(subset=['source_article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef122f1b975e9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T17:56:33.758683700Z",
     "start_time": "2024-09-05T17:56:33.714654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.groupby(\"source_article\")['logical_fallacies'].agg(lambda x: list(x)).reset_index()\n",
    "test = test.groupby(\"source_article\")['logical_fallacies'].agg(lambda x: list(x)).reset_index()\n",
    "dev = dev.groupby(\"source_article\")['logical_fallacies'].agg(lambda x: list(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4273efe8bc8a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T17:56:35.490710500Z",
     "start_time": "2024-09-05T17:56:35.444655600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"data/logicclimate/multi_train.csv\")\n",
    "test.to_csv(\"data/logicclimate/multi_test.csv\")\n",
    "dev.to_csv(\"data/logicclimate/multi_dev.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

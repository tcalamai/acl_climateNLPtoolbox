{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "def format_page_dataset(json_data):\n",
    "    sentences = []\n",
    "    label = []\n",
    "    sentences_id = []\n",
    "    document_id = []\n",
    "    page_id = []\n",
    "\n",
    "    for document in json_data:\n",
    "        _sentence_ids = []\n",
    "        for evidence in document['meta']['evidences']:\n",
    "            _sentence_ids += evidence[0]['sentence_ids']\n",
    "            \n",
    "        for sentence in document[\"sentences\"]:\n",
    "            sentences.append(sentence['text'])\n",
    "            label.append(1*(sentence['sentence_id'] in _sentence_ids ))\n",
    "            sentences_id.append(sentence['sentence_id'])\n",
    "            document_id.append(document['document_id'])\n",
    "            page_id.append(sentence['page_idx'])\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'sentences': sentences,\n",
    "        'label': label,\n",
    "        'sentence_id': sentences_id,\n",
    "        'document_id': document_id,\n",
    "        'page_id': page_id\n",
    "    })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data\\\\lobbymap\\\\lobbymap_dataset\"\n",
    "\n",
    "# train\n",
    "file_path = folder_path + \"\\\\train.jsonl\"\n",
    "jsonl_train = read_jsonl(file_path)\n",
    "df_train = format_page_dataset(jsonl_train)\n",
    "\n",
    "\n",
    "file_path = folder_path + \"\\\\test.jsonl\"\n",
    "jsonl_test = read_jsonl(file_path)\n",
    "df_test = format_page_dataset(jsonl_test)\n",
    "\n",
    "\n",
    "file_path = folder_path + \"\\\\valid.jsonl\"\n",
    "jsonl_dev = read_jsonl(file_path)\n",
    "df_dev = format_page_dataset(jsonl_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def train_baselines(X_train, y_train, seed, model=\"tfidf + LogReg\"):\n",
    "    if X_train.shape[0] != len(y_train):\n",
    "        raise ValueError(\"X_train and y_train should have the same number of samples.\")\n",
    "\n",
    "    pipelines = {\n",
    "        \"tfidf + LogReg\": make_pipeline(TfidfVectorizer(), LogisticRegression(class_weight='balanced', max_iter=1000, random_state=seed)),\n",
    "        \"random\": make_pipeline(DummyClassifier(strategy=\"uniform\")),\n",
    "        \"majority\": make_pipeline(DummyClassifier(strategy=\"most_frequent\"))\n",
    "    }\n",
    "\n",
    "    pipe = pipelines[model]\n",
    "    pipe.fit(X=X_train, y=y_train)\n",
    "\n",
    "    return pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['sentences']\n",
    "y_train = df_train['label']\n",
    "\n",
    "pipe_page = train_baselines(X_train=X_train, y_train=y_train, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88    429503\n",
      "           1       0.14      0.74      0.23     18760\n",
      "\n",
      "    accuracy                           0.80    448263\n",
      "   macro avg       0.56      0.77      0.56    448263\n",
      "weighted avg       0.95      0.80      0.86    448263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conventional eval: \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_test = df_test['sentences']\n",
    "y_test = df_test['label']\n",
    "\n",
    "y_pred = pipe_page.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_query_dataset(json_data):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for document in json_data:\n",
    "        page_ids = []\n",
    "        query = []\n",
    "        stance = []\n",
    "        for evidence in document['evidences']:\n",
    "            page_ids += [evidence['page_indices']]\n",
    "            query += [evidence['query']]\n",
    "            stance += [evidence['stance']]\n",
    "        \n",
    "        _df = pd.DataFrame({\n",
    "        'page_id': page_ids,\n",
    "        \"query\": query,\n",
    "        \"stance\": stance\n",
    "        })\n",
    "        \n",
    "        _df['document_id'] = document['document_id']\n",
    "        _df = _df.explode(column=['page_id'])\n",
    "        df = pd.concat([df, _df])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_train = format_query_dataset(jsonl_train)\n",
    "df_query_test = format_query_dataset(jsonl_test)\n",
    "df_query_dev = format_query_dataset(jsonl_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sort_values(by=['sentence_id'], inplace=True)\n",
    "df_test.sort_values(by=['sentence_id'], inplace=True)\n",
    "df_dev.sort_values(by=['sentence_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_train = df_train.groupby(['document_id', 'page_id'])['sentences'].apply(lambda x: ' '.join(x))\n",
    "page_test = df_test.groupby(['document_id', 'page_id'])['sentences'].apply(lambda x: ' '.join(x))\n",
    "page_dev = df_dev.groupby(['document_id', 'page_id'])['sentences'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_train = page_train.reset_index()\n",
    "page_test = page_test.reset_index()\n",
    "page_dev = page_dev.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_train = page_train.merge(df_query_train, how=\"left\", on=[\"document_id\", \"page_id\"])\n",
    "page_test = page_test.merge(df_query_test, how=\"left\", on=[\"document_id\", \"page_id\"])\n",
    "page_dev = page_dev.merge(df_query_dev, how=\"left\", on=[\"document_id\", \"page_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "def train_baselines_multilabel(X_train, y_train, seed, model=\"tfidf + LogReg\"):\n",
    "    if X_train.shape[0] != len(y_train):\n",
    "        raise ValueError(\"X_train and y_train should have the same number of samples.\")\n",
    "\n",
    "    pipelines = {\n",
    "        \"tfidf + LogReg\": make_pipeline(TfidfVectorizer(), MultiOutputClassifier(LogisticRegression(class_weight='balanced', max_iter=1000, random_state=seed))),\n",
    "        \"random\": make_pipeline(DummyClassifier(strategy=\"uniform\", random_state=seed)),\n",
    "        \"majority\": make_pipeline(DummyClassifier(strategy=\"most_frequent\", random_state=seed))\n",
    "    }\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_train_bin = mlb.fit_transform(y_train)\n",
    "\n",
    "    pipe = pipelines[model]\n",
    "    pipe.fit(X=X_train, y=y_train_bin)\n",
    "\n",
    "    return pipe, mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ds = page_train[~page_train['query'].isna()].groupby(['document_id', 'page_id', 'sentences'])['query'].apply(lambda x: [e for e in x]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = query_ds['sentences']\n",
    "y_train = query_ds['query']\n",
    "\n",
    "pipe_query, mlb = train_baselines_multilabel(X_train=X_train, y_train=y_train, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ds_test = page_test[~page_test['query'].isna()].groupby(['document_id', 'page_id', 'sentences'])['query'].apply(lambda x: [e for e in x]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.64      0.42       364\n",
      "           1       0.34      0.56      0.42        87\n",
      "           2       0.37      0.71      0.49       149\n",
      "           3       0.52      0.74      0.61        47\n",
      "           4       0.54      0.47      0.50       226\n",
      "           5       0.55      0.52      0.53       197\n",
      "           6       0.83      0.84      0.84      2260\n",
      "           7       0.50      0.65      0.57       399\n",
      "           8       0.51      0.57      0.54        49\n",
      "           9       0.41      0.66      0.51       290\n",
      "          10       0.29      0.70      0.41       172\n",
      "          11       0.33      0.62      0.43       345\n",
      "          12       0.14      0.36      0.21        44\n",
      "\n",
      "   micro avg       0.55      0.73      0.63      4629\n",
      "   macro avg       0.43      0.62      0.50      4629\n",
      "weighted avg       0.61      0.73      0.65      4629\n",
      " samples avg       0.62      0.75      0.65      4629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# conventional eval: \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_test = query_ds_test['sentences']\n",
    "y_test = query_ds_test['query']\n",
    "\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "\n",
    "y_pred_query = pipe_query.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true=y_test_bin, y_pred=y_pred_query, zero_division=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def train_baselines_query_onehot(X_train, y_train, seed, model=\"tfidf + LogReg\"):\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(), 'sentences'),\n",
    "            ('query', OneHotEncoder(), ['query'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipelines = {\n",
    "        \"tfidf + LogReg\": make_pipeline(preprocessor, LogisticRegression(class_weight='balanced', max_iter=1000, random_state=seed)),\n",
    "        \"random\": make_pipeline(DummyClassifier(strategy=\"uniform\", random_state=seed)),\n",
    "        \"majority\": make_pipeline(DummyClassifier(strategy=\"most_frequent\", random_state=seed))\n",
    "    }\n",
    "\n",
    "    pipe = pipelines[model]\n",
    "    pipe.fit(X=X_train, y=y_train)\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "stance_ds = page_train[~page_train['query'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = stance_ds[['sentences', 'query']]\n",
    "y_train = stance_ds['stance']\n",
    "\n",
    "pipe_stance = train_baselines_query_onehot(X_train=X_train, y_train=y_train, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               precision    recall  f1-score   support\n",
      "\n",
      "no_position_or_mixed_position       0.43      0.43      0.43      1031\n",
      "               not_supporting       0.45      0.47      0.46       930\n",
      "                     opposing       0.30      0.37      0.33       468\n",
      "          strongly_supporting       0.45      0.53      0.49       729\n",
      "                   supporting       0.58      0.48      0.52      1560\n",
      "\n",
      "                     accuracy                           0.46      4718\n",
      "                    macro avg       0.44      0.46      0.45      4718\n",
      "                 weighted avg       0.47      0.46      0.47      4718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stance_ds_test = page_test[~page_test['query'].isna()].copy()\n",
    "\n",
    "X_test = stance_ds_test[['sentences', 'query']]\n",
    "y_test_stance = stance_ds_test['stance']\n",
    "\n",
    "y_pred_stance = pipe_stance.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true=y_test_stance, y_pred=y_pred_stance, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['y_pred'] = y_pred\n",
    "query_ds_test['y_pred_query'] = mlb.inverse_transform(y_pred_query)\n",
    "stance_ds_test['y_pred_stance'] = y_pred_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_page_idx_classifier = page_train.groupby(['document_id', 'page_id', 'sentences'])['query'].agg(lambda x: ~x.isna().all()).reset_index()\n",
    "test_page_idx_classifier = page_test.groupby(['document_id', 'page_id', 'sentences'])['query'].agg(lambda x: ~x.isna().all()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full page learning: \n",
    "X_train = train_page_idx_classifier['sentences']\n",
    "y_train = train_page_idx_classifier['query']\n",
    "\n",
    "pipe_page_entire = train_baselines(X_train=X_train, y_train=y_train, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.78      0.85     11938\n",
      "        True       0.54      0.78      0.64      3817\n",
      "\n",
      "    accuracy                           0.78     15755\n",
      "   macro avg       0.73      0.78      0.74     15755\n",
      "weighted avg       0.83      0.78      0.80     15755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_entire = test_page_idx_classifier['sentences']\n",
    "y_test_entire = test_page_idx_classifier['query']\n",
    "\n",
    "y_pred_entire = pipe_page_entire.predict(X_test_entire)\n",
    "\n",
    "print(classification_report(y_true=y_test_entire, y_pred=y_pred_entire, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_page_idx_classifier['y_pred_entire'] = y_pred_entire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_pages = df_test.groupby(['document_id', 'page_id'])['y_pred'].apply(lambda x: sum(x)>1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_pages = test_page_idx_classifier[['document_id', 'page_id', 'y_pred_entire']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_page_test = page_test.merge(detected_pages, how='left', on=['document_id', 'page_id'], suffixes=(\"\",\"_page\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_detected = detected_page_test['sentences']\n",
    "\n",
    "y_q = pipe_query.predict(X_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_page_test['y_pred_query'] = mlb.inverse_transform(y_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_query = detected_page_test.explode('y_pred_query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_detected = exploded_query[~exploded_query['y_pred_query'].isna()][['sentences', 'y_pred_query']].copy()\n",
    "X_detected = X_detected.rename(columns={\"y_pred_query\":\"query\"})\n",
    "\n",
    "y_s = pipe_stance.predict(X_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_query.loc[~exploded_query['y_pred_query'].isna(), 'y_pred_stance'] = y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_triplet = exploded_query[['document_id', 'page_id', 'query', 'stance']].drop_duplicates(keep=\"first\").explode('query')\n",
    "gold_triplet = gold_triplet[~gold_triplet['query'].isna()]\n",
    "gold_triplet = gold_triplet.groupby(by=['document_id', 'query', 'stance'])['page_id'].agg(lambda x: [e for e in x]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_query.rename(columns={\"y_pred_entire\":\"y_pred\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_triplet = exploded_query[exploded_query['y_pred']].copy()\n",
    "pred_triplet = pred_triplet[['document_id', 'page_id', 'y_pred_query', 'y_pred_stance']].drop_duplicates(keep=\"first\")\n",
    "pred_triplet = pred_triplet[~pred_triplet['y_pred_query'].isna()]\n",
    "pred_triplet = pred_triplet.groupby(by=['document_id', 'y_pred_query', 'y_pred_stance'])['page_id'].agg(lambda x: [e for e in x]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_jds = []\n",
    "for document_id in pred_triplet['document_id'].unique():\n",
    "    pred_evidences = []\n",
    "    for i, r in pred_triplet[pred_triplet['document_id'] == document_id].iterrows():\n",
    "        pred_evidences.append({\n",
    "            \"query\": r['y_pred_query'],\n",
    "            \"stance\": r['y_pred_stance'],\n",
    "            \"page_indices\": r['page_id']\n",
    "        })\n",
    "    \n",
    "    pred_jds.append({\n",
    "        'document_id': document_id,\n",
    "        'evidences': pred_evidences\n",
    "    })\n",
    "\n",
    "gold_jds = []\n",
    "for document_id in gold_triplet['document_id'].unique():\n",
    "    gold_evidences = []\n",
    "    for i, r in gold_triplet[gold_triplet['document_id'] == document_id].iterrows():\n",
    "        gold_evidences.append({\n",
    "            \"query\": r['query'],\n",
    "            \"stance\": r['stance'],\n",
    "            \"page_indices\": r['page_id']\n",
    "        })\n",
    "    \n",
    "    gold_jds.append({\n",
    "        'document_id': document_id,\n",
    "        'evidences': gold_evidences\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF & 63.5 & 57.4 & 50.2 & 65.9 & 42.6 & 34.7 & 39.3 & 25.5 & 20.9 \\\\\n"
     ]
    }
   ],
   "source": [
    "from src.lobbymap.evaluate_f1 import evaluate_strict_f1, evaluate_overlap_f1, evaluate_document_f1\n",
    "\n",
    "result_strict = evaluate_strict_f1(gold_jds=gold_jds, pred_jds=pred_jds)\n",
    "result_document = evaluate_document_f1(gold_jds=gold_jds, pred_jds=pred_jds)\n",
    "result_overlap = evaluate_overlap_f1(gold_jds=gold_jds, pred_jds=pred_jds)\n",
    "\n",
    "\n",
    "print(\"TF-IDF\", \"&\", result_document['page']['f'], \"&\", result_document['query']['f'], \"&\", result_document['stance']['f'], \"&\", result_overlap['page']['f'], \"&\", result_overlap['query']['f'], \"&\", result_overlap['stance']['f'], \"&\", result_strict['page']['f'], \"&\", result_strict['query']['f'], \"&\", result_strict['stance']['f'], \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_jds = []\n",
    "for document_id in gold_triplet['document_id'].unique():\n",
    "    gold_evidences = []\n",
    "    for i, r in gold_triplet[gold_triplet['document_id'] == document_id].iterrows():\n",
    "        gold_evidences.append({\n",
    "            \"query\": r['query'],\n",
    "            \"stance\": r['stance'],\n",
    "            \"page_indices\": r['page_id']\n",
    "        })\n",
    "    \n",
    "    gold_jds.append({\n",
    "        'document_id': document_id,\n",
    "        'evidences': gold_evidences\n",
    "    })\n",
    "\n",
    "pred_jds = []\n",
    "for document_id in gold_triplet['document_id'].unique():\n",
    "    pred_evidences = [{\n",
    "            \"query\": \"energy_transition_&_zero_carbon_technologies\",\n",
    "            \"stance\": \"supporting\",\n",
    "            \"page_indices\": [0]\n",
    "        }]\n",
    "    \n",
    "    pred_jds.append({\n",
    "        'document_id': document_id,\n",
    "        'evidences': pred_evidences\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequent & 46.7 & 52.6 & 36.8 & 52.0 & 25.7 & 19.8 & 41.2 & 19.6 & 17.5 \\\\\n"
     ]
    }
   ],
   "source": [
    "from src.lobbymap.evaluate_f1 import evaluate_strict_f1, evaluate_overlap_f1, evaluate_document_f1\n",
    "\n",
    "result_strict = evaluate_strict_f1(gold_jds=gold_jds, pred_jds=pred_jds)\n",
    "result_document = evaluate_document_f1(gold_jds=gold_jds, pred_jds=pred_jds)\n",
    "result_overlap = evaluate_overlap_f1(gold_jds=gold_jds, pred_jds=pred_jds)\n",
    "\n",
    "\n",
    "print(\"Most Frequent\", \"&\", result_document['page']['f'], \"&\", result_document['query']['f'], \"&\", result_document['stance']['f'], \"&\", result_overlap['page']['f'], \"&\", result_overlap['query']['f'], \"&\", result_overlap['stance']['f'], \"&\", result_strict['page']['f'], \"&\", result_strict['query']['f'], \"&\", result_strict['stance']['f'], \"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
